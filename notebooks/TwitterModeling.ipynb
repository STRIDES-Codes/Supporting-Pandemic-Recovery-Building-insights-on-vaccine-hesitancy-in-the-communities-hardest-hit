{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4757390e",
   "metadata": {},
   "source": [
    "# Twitter Mining & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930c201",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cc0664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dff71936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "69bd9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(API_key, API_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db1a57",
   "metadata": {},
   "source": [
    "#### Query the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "0a928057",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"covax vaccine vaccination vax hoax #idonotconsent -filter:retweets\"\n",
    "date_since = \"2020-12-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "56653468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search: #0\n",
      "New data count: 8237\n",
      "Starting search: #1\n",
      "New data count: 8237\n",
      "Starting search: #2\n",
      "New data count: 8237\n",
      "Starting search: #3\n",
      "New data count: 8237\n",
      "Starting search: #4\n",
      "New data count: 8237\n",
      "Starting search: #5\n",
      "New data count: 8237\n",
      "Starting search: #6\n",
      "New data count: 8237\n",
      "Starting search: #7\n",
      "New data count: 8237\n",
      "Starting search: #8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-e791361cdeed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/twitter_search.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcsvWriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtweets_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtweets_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# Execute request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                     resp = self.session.request(self.method,\n\u001b[0m\u001b[1;32m    185\u001b[0m                                                 \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                                                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_default_certs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[1;32m    412\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mkeyfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msend_sni\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         ssl_sock = _ssl_wrap_socket_impl(\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtls_in_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# SSLSocket class handles server_hostname encoding before it calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mserver_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_side\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1038\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f\"Starting search: #{i}\")\n",
    "    tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since).items(1000)\n",
    "    \n",
    "    with open(\"../data/twitter_search.csv\", 'a', newline='') as csvFile:\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        for tweet in tweets:\n",
    "            tweets_encoded = tweet.text.encode('utf-8')\n",
    "            tweets_decoded = tweets_encoded.decode('utf-8')\n",
    "            if tweet.id not in ids:\n",
    "                csvWriter.writerow([tweet.id, tweets_decoded, tweet.created_at, tweet.geo, tweet.place.name if tweet.place else None, tweet.coordinates, tweet._json[\"user\"][\"location\"]])\n",
    "\n",
    "    twitter_df = pd.read_csv(\"../data/twitter_search.csv\", \n",
    "                         names=[\"id\", \"tweet\", \"date\", \"drop0\", \"drop1\", \"drop2\", \"location\"])\n",
    "    \n",
    "    print(f\"New data count: {len(twitter_df)}\")\n",
    "    ids = twitter_df.id.to_list()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f627a8a",
   "metadata": {},
   "source": [
    "#### Apparently the free API limits you to just a week's worth of data :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "8bd7e5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>drop0</th>\n",
       "      <th>drop1</th>\n",
       "      <th>drop2</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1407417288106680322</td>\n",
       "      <td>@MLAStefanson @mingoertzen @BrianPallister tha...</td>\n",
       "      <td>2021-06-22 19:16:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YWG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1407417265994223622</td>\n",
       "      <td>@akelvinlab But Pfizer Fact Sheet for Health C...</td>\n",
       "      <td>2021-06-22 19:16:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1407417186948243458</td>\n",
       "      <td>Vaccination centers for 18-44 age group: \\n1. ...</td>\n",
       "      <td>2021-06-22 19:16:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hyderabad, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1407417182577889281</td>\n",
       "      <td>@peterktodd „WHO's Strategic Advisory Group of...</td>\n",
       "      <td>2021-06-22 19:16:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cologne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1407417156032155651</td>\n",
       "      <td>@Truthseeker1985 This turd also ignores Expert...</td>\n",
       "      <td>2021-06-22 19:16:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "0  1407417288106680322  @MLAStefanson @mingoertzen @BrianPallister tha...   \n",
       "1  1407417265994223622  @akelvinlab But Pfizer Fact Sheet for Health C...   \n",
       "2  1407417186948243458  Vaccination centers for 18-44 age group: \\n1. ...   \n",
       "3  1407417182577889281  @peterktodd „WHO's Strategic Advisory Group of...   \n",
       "4  1407417156032155651  @Truthseeker1985 This turd also ignores Expert...   \n",
       "\n",
       "                  date  drop0 drop1  drop2          location  \n",
       "0  2021-06-22 19:16:44    NaN   NaN    NaN               YWG  \n",
       "1  2021-06-22 19:16:39    NaN   NaN    NaN               NaN  \n",
       "2  2021-06-22 19:16:20    NaN   NaN    NaN  Hyderabad, India  \n",
       "3  2021-06-22 19:16:19    NaN   NaN    NaN           Cologne  \n",
       "4  2021-06-22 19:16:13    NaN   NaN    NaN               NaN  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "f9573ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = twitter_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "61caf504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5436"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "52799f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enceladosaurus/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"drop0\", \"drop1\", \"drop2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7e65da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"date\", \"location\", \"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "aa86a4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MLAStefanson @mingoertzen @BrianPallister tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@akelvinlab But Pfizer Fact Sheet for Health C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaccination centers for 18-44 age group: \\n1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@peterktodd „WHO's Strategic Advisory Group of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Truthseeker1985 This turd also ignores Expert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  @MLAStefanson @mingoertzen @BrianPallister tha...\n",
       "1  @akelvinlab But Pfizer Fact Sheet for Health C...\n",
       "2  Vaccination centers for 18-44 age group: \\n1. ...\n",
       "3  @peterktodd „WHO's Strategic Advisory Group of...\n",
       "4  @Truthseeker1985 This turd also ignores Expert..."
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b63c032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/cleaned_twitter.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695ce86",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "484c9433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/enceladosaurus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/enceladosaurus/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/enceladosaurus/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f553b6b",
   "metadata": {},
   "source": [
    "### Sentiment140 Dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f53992",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "01a932c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_training = pd.read_csv(\"../data/twitter_training.csv\", names=[\"positivity\", \"tweetid\", \"date\", \"query\", \"user\", \"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5fa3dd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positivity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positivity                                              tweet\n",
       "0           0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1           0  is upset that he can't update his Facebook by ...\n",
       "2           0  @Kenichan I dived many times for the ball. Man...\n",
       "3           0    my whole body feels itchy and like its on fire \n",
       "4           0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "09ec96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter_training.drop([\"tweetid\", \"date\", \"query\", \"user\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "213395f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_training.positivity = twitter_training.positivity.replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d4a84aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = twitter_training[twitter_training.positivity == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "79980978",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = twitter_training[twitter_training.positivity == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef6ef7",
   "metadata": {},
   "source": [
    "### Clean Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e7e01c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "eec70ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tweets = negative.tweet.to_list()\n",
    "positive_tweets = positive.tweet.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "52064f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ddb8d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "82aa47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(token_list: list) -> list:\n",
    "    lemmatized_tokens = []\n",
    "    for token, tag in pos_tag(token_list):\n",
    "        if tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        elif tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token, pos))\n",
    "    \n",
    "    return lemmatized_tokens   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2171cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(token_list: list, stop_words: list) -> list:\n",
    "    trim_characters = ['!', '.', ',', '*', '&', '%', '$', '?', '\"\"', \":\", \";\", \"(\", \")\", \"-\", \"/\"]\n",
    "    remove_characters = ['@', '#', '//']\n",
    "    cleaned_tokens = []\n",
    "    \n",
    "    for token in token_list:\n",
    "        for character in trim_characters:\n",
    "            if character in token:\n",
    "                token = token.strip(character)\n",
    "        for character in remove_characters:\n",
    "            if character in token:\n",
    "                token = ''\n",
    "                \n",
    "        if len(token) > 1 and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token)\n",
    "    \n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "961c7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a22ec61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_data  = [tweet_tokenizer.tokenize(x) for x in negative_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "28b1f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data  = [tweet_tokenizer.tokenize(x) for x in positive_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "41a32f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(tweet: str) -> list:\n",
    "    token_list = tweet_tokenizer.tokenize(tweet)\n",
    "    stop_words = stopwords.words('english')\n",
    "    cleaned_tokens = clean_data(token_list, stop_words)\n",
    "    lemmatized_tokens = lemmatize(cleaned_tokens)\n",
    "    \n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "da3f67ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(all_tokens: list, stop_words: list):\n",
    "    cleaned_data = []\n",
    "    for token_list in all_tokens:\n",
    "        cleaned_tokens = clean_data(token_list, stop_words)\n",
    "        lemmatized_tokens = lemmatize(cleaned_tokens)\n",
    "        cleaned_data.append(lemmatized_tokens)\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "adc6530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_negative = prepare_data(negative_data, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "9b59ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_positive = prepare_data(positive_data, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8cf4444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(all_tokens: list) -> dict:\n",
    "    for token_list in all_tokens:\n",
    "        yield dict([token, True] for token in token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a8e54e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_model(positive_tokens: list, negative_tokens: list) -> list:\n",
    "    positive_tweets = [(positive_dict, \"Positive\") for positive_dict in convert_to_dict(positive_tokens)]\n",
    "    negative_tweets = [(negative_dict, \"Negative\") for negative_dict in convert_to_dict(negative_tokens)]\n",
    "    \n",
    "    return positive_tweets + negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "857c92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = prepare_data_for_model(cleaned_positive, cleaned_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053b836",
   "metadata": {},
   "source": [
    "## Sklearn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "14096157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "459e5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_processing)),  \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', MultinomialNB()), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "2a7e38b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positivity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positivity                                              tweet\n",
       "0           0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1           0  is upset that he can't update his Facebook by ...\n",
       "2           0  @Kenichan I dived many times for the ball. Man...\n",
       "3           0    my whole body feels itchy and like its on fire \n",
       "4           0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a039ba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76    162927\n",
      "           1       0.75      0.76      0.75    157073\n",
      "\n",
      "    accuracy                           0.76    320000\n",
      "   macro avg       0.76      0.76      0.76    320000\n",
      "weighted avg       0.76      0.76      0.76    320000\n",
      "\n",
      "[[122701  40226]\n",
      " [ 37709 119364]]\n",
      "0.756453125\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(twitter_training['tweet'], twitter_training['positivity'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ce759",
   "metadata": {},
   "source": [
    "## NLTK Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f467ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "067c51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "097bba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8252c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_tweets[:round(len(all_tweets) * 0.2)]\n",
    "test = all_tweets[round(len(all_tweets) * 0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "fd9125fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0ac96b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75542109375"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.accuracy(nbc, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "e97e94f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 saddest = True           Negati : Positi =     37.5 : 1.0\n",
      "                  farrah = True           Negati : Positi =     29.5 : 1.0\n",
      "                  poorly = True           Negati : Positi =     26.1 : 1.0\n",
      "                  arghhh = True           Negati : Positi =     24.9 : 1.0\n",
      "                 honored = True           Positi : Negati =     24.4 : 1.0\n",
      "             condolences = True           Negati : Positi =     24.3 : 1.0\n",
      "                saddened = True           Negati : Positi =     23.6 : 1.0\n",
      "                  boohoo = True           Negati : Positi =     21.6 : 1.0\n",
      "                   arghh = True           Negati : Positi =     20.9 : 1.0\n",
      "                  gutted = True           Negati : Positi =     20.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nbc.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "19f9b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df.tweet.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6ac9992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vax_data = [tweet_tokenizer.tokenize(x) for x in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ee253091",
   "metadata": {},
   "outputs": [],
   "source": [
    "vax_tweets = prepare_data(vax_data, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "0ab148ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.classify(dict([token, True] for token in vax_tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "709113cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = []\n",
    "positives = []\n",
    "for tweet in vax_tweets:\n",
    "    if nbc.classify(dict([token, True] for token in tweet)) == 'Negative':\n",
    "        negatives.append(tweet)\n",
    "    else:\n",
    "        positives.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "962cffcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3416114790286976"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positives)/len(vax_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e70a192a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6583885209713024"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negatives)/len(vax_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "5af7a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tokens = []\n",
    "for tweet in negatives:\n",
    "    for token in tweet:\n",
    "        negative_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e6116c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tokens = []\n",
    "for tweet in positives:\n",
    "    for token in tweet:\n",
    "        positive_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "73bb4572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38463"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f6a2bec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19231"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "64ba54d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_list = list(set(positive_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a8f97f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = [positive_tokens.count(x) for x in positive_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "267591d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dict = {\n",
    "    \"token\" : positive_list,\n",
    "    \"count\" : positive_counts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "9df7e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.DataFrame.from_dict(positive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "3f59bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df.sort_values(by=\"count\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4f769657",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df[\"prevalence\"] = positive_df[\"count\"] / len(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "d7512063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>vaccination</td>\n",
       "      <td>924</td>\n",
       "      <td>0.497577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>vaccine</td>\n",
       "      <td>665</td>\n",
       "      <td>0.358104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>covid</td>\n",
       "      <td>374</td>\n",
       "      <td>0.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>19</td>\n",
       "      <td>270</td>\n",
       "      <td>0.145396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>available</td>\n",
       "      <td>167</td>\n",
       "      <td>0.089930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>doses</td>\n",
       "      <td>152</td>\n",
       "      <td>0.081852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>appointments</td>\n",
       "      <td>126</td>\n",
       "      <td>0.067851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>jun</td>\n",
       "      <td>124</td>\n",
       "      <td>0.066774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>sign</td>\n",
       "      <td>122</td>\n",
       "      <td>0.065697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>code</td>\n",
       "      <td>120</td>\n",
       "      <td>0.064620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  count  prevalence\n",
       "1833   vaccination    924    0.497577\n",
       "1573       vaccine    665    0.358104\n",
       "965          covid    374    0.201400\n",
       "1284            19    270    0.145396\n",
       "4215     available    167    0.089930\n",
       "202          doses    152    0.081852\n",
       "117   appointments    126    0.067851\n",
       "596            jun    124    0.066774\n",
       "2884          sign    122    0.065697\n",
       "1812          code    120    0.064620"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "17f797d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = list(set(negative_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "be223c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = [negative_tokens.count(x) for x in token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "0bcd1431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_counts) == len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "8f25cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {\n",
    "    \"token\" : token_list,\n",
    "    \"count\" : token_counts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "abb1fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = pd.DataFrame.from_dict(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7de4af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df.sort_values(by=\"count\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b7269ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4098910310142498"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1467/len(negatives) # \"Available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "25e858ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23190835428890752"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "830/len(negatives) #appointments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "454318db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10220486908589803"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "445/len(negatives) # slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8cc5cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21497473587505742"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "936 / len(negatives) # walgreens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "59d42a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df[\"prevalence\"] = token_df[\"count\"] / len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "a495201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = []\n",
    "for tweet in negatives:\n",
    "    if \"sign\" in tweet:\n",
    "        signs.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "8bd649e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>vaccine</td>\n",
       "      <td>2283</td>\n",
       "      <td>0.637888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>vaccination</td>\n",
       "      <td>1467</td>\n",
       "      <td>0.409891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5783</th>\n",
       "      <td>available</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.351215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>appointments</td>\n",
       "      <td>830</td>\n",
       "      <td>0.231908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>walgreens</td>\n",
       "      <td>817</td>\n",
       "      <td>0.228276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>sign</td>\n",
       "      <td>776</td>\n",
       "      <td>0.216820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>code</td>\n",
       "      <td>775</td>\n",
       "      <td>0.216541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>jun</td>\n",
       "      <td>775</td>\n",
       "      <td>0.216541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>zip</td>\n",
       "      <td>773</td>\n",
       "      <td>0.215982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>jul</td>\n",
       "      <td>772</td>\n",
       "      <td>0.215703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>covid</td>\n",
       "      <td>578</td>\n",
       "      <td>0.161498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>chicago</td>\n",
       "      <td>551</td>\n",
       "      <td>0.153954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>22</td>\n",
       "      <td>482</td>\n",
       "      <td>0.134674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>slot</td>\n",
       "      <td>412</td>\n",
       "      <td>0.115116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>19</td>\n",
       "      <td>346</td>\n",
       "      <td>0.096675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>23</td>\n",
       "      <td>345</td>\n",
       "      <td>0.096396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>age</td>\n",
       "      <td>288</td>\n",
       "      <td>0.080469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>get</td>\n",
       "      <td>253</td>\n",
       "      <td>0.070690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>2021</td>\n",
       "      <td>208</td>\n",
       "      <td>0.058117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>june</td>\n",
       "      <td>203</td>\n",
       "      <td>0.056720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  count  prevalence\n",
       "541        vaccine   2283    0.637888\n",
       "5032   vaccination   1467    0.409891\n",
       "5783     available   1257    0.351215\n",
       "4474  appointments    830    0.231908\n",
       "3369     walgreens    817    0.228276\n",
       "5366          sign    776    0.216820\n",
       "2083          code    775    0.216541\n",
       "1701           jun    775    0.216541\n",
       "2859           zip    773    0.215982\n",
       "1543           jul    772    0.215703\n",
       "1808         covid    578    0.161498\n",
       "1023       chicago    551    0.153954\n",
       "4566            22    482    0.134674\n",
       "3117          slot    412    0.115116\n",
       "1915            19    346    0.096675\n",
       "1516            23    345    0.096396\n",
       "2847           age    288    0.080469\n",
       "3316           get    253    0.070690\n",
       "555           2021    208    0.058117\n",
       "5130          june    203    0.056720"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "29c5274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df.to_csv(\"../data/token_prevalence.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nih",
   "language": "python",
   "name": "nih"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
