{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be586df",
   "metadata": {},
   "source": [
    "# Twitter Mining & Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd3ce1",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cc0664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dff71936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "69bd9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(API_key, API_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8234e7",
   "metadata": {},
   "source": [
    "#### Query the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0a928057",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"covax vaccine vaccination vax hoax #idonotconsent -filter:retweets\"\n",
    "date_since = \"2020-12-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "247dc9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search: #0\n",
      "New data count: 8237\n",
      "Starting search: #1\n",
      "New data count: 8237\n",
      "Starting search: #2\n",
      "New data count: 8237\n",
      "Starting search: #3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-e791361cdeed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/twitter_search.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcsvWriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtweets_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtweets_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# Execute request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                     resp = self.session.request(self.method,\n\u001b[0m\u001b[1;32m    185\u001b[0m                                                 \u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                                                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f\"Starting search: #{i}\")\n",
    "    tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since).items(1000)\n",
    "    \n",
    "    with open(\"../data/twitter_search.csv\", 'a', newline='') as csvFile:\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        for tweet in tweets:\n",
    "            tweets_encoded = tweet.text.encode('utf-8')\n",
    "            tweets_decoded = tweets_encoded.decode('utf-8')\n",
    "            if tweet.id not in ids:\n",
    "                csvWriter.writerow([tweet.id, tweets_decoded, tweet.created_at, tweet.geo, tweet.place.name if tweet.place else None, tweet.coordinates, tweet._json[\"user\"][\"location\"]])\n",
    "\n",
    "    twitter_df = pd.read_csv(\"../data/twitter_search.csv\", \n",
    "                         names=[\"id\", \"tweet\", \"date\", \"drop0\", \"drop1\", \"drop2\", \"location\"])\n",
    "    \n",
    "    print(f\"New data count: {len(twitter_df)}\")\n",
    "    ids = twitter_df.id.to_list()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e690d9f",
   "metadata": {},
   "source": [
    "#### Apparently the free API limits you to just a week's worth of data :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8bd7e5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>date</th>\n",
       "      <th>drop0</th>\n",
       "      <th>drop1</th>\n",
       "      <th>drop2</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1407417288106680322</td>\n",
       "      <td>@MLAStefanson @mingoertzen @BrianPallister tha...</td>\n",
       "      <td>2021-06-22 19:16:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YWG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1407417265994223622</td>\n",
       "      <td>@akelvinlab But Pfizer Fact Sheet for Health C...</td>\n",
       "      <td>2021-06-22 19:16:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1407417186948243458</td>\n",
       "      <td>Vaccination centers for 18-44 age group: \\n1. ...</td>\n",
       "      <td>2021-06-22 19:16:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hyderabad, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1407417182577889281</td>\n",
       "      <td>@peterktodd „WHO's Strategic Advisory Group of...</td>\n",
       "      <td>2021-06-22 19:16:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cologne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1407417156032155651</td>\n",
       "      <td>@Truthseeker1985 This turd also ignores Expert...</td>\n",
       "      <td>2021-06-22 19:16:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                              tweet  \\\n",
       "0  1407417288106680322  @MLAStefanson @mingoertzen @BrianPallister tha...   \n",
       "1  1407417265994223622  @akelvinlab But Pfizer Fact Sheet for Health C...   \n",
       "2  1407417186948243458  Vaccination centers for 18-44 age group: \\n1. ...   \n",
       "3  1407417182577889281  @peterktodd „WHO's Strategic Advisory Group of...   \n",
       "4  1407417156032155651  @Truthseeker1985 This turd also ignores Expert...   \n",
       "\n",
       "                  date  drop0 drop1  drop2          location  \n",
       "0  2021-06-22 19:16:44    NaN   NaN    NaN               YWG  \n",
       "1  2021-06-22 19:16:39    NaN   NaN    NaN               NaN  \n",
       "2  2021-06-22 19:16:20    NaN   NaN    NaN  Hyderabad, India  \n",
       "3  2021-06-22 19:16:19    NaN   NaN    NaN           Cologne  \n",
       "4  2021-06-22 19:16:13    NaN   NaN    NaN               NaN  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "20f4262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = twitter_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "457b836a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5436"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "975c9b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enceladosaurus/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"drop0\", \"drop1\", \"drop2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dbb30615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"date\", \"location\", \"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3db16013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MLAStefanson @mingoertzen @BrianPallister tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@akelvinlab But Pfizer Fact Sheet for Health C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vaccination centers for 18-44 age group: \\n1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@peterktodd „WHO's Strategic Advisory Group of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Truthseeker1985 This turd also ignores Expert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  @MLAStefanson @mingoertzen @BrianPallister tha...\n",
       "1  @akelvinlab But Pfizer Fact Sheet for Health C...\n",
       "2  Vaccination centers for 18-44 age group: \\n1. ...\n",
       "3  @peterktodd „WHO's Strategic Advisory Group of...\n",
       "4  @Truthseeker1985 This turd also ignores Expert..."
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "794dc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/cleaned_twitter.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4f75d3",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a4a8aa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/enceladosaurus/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/enceladosaurus/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/enceladosaurus/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dff9aa",
   "metadata": {},
   "source": [
    "### Sentiment140 Dataset for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbafff47",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e50a4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_training = pd.read_csv(\"../data/twitter_training.csv\", names=[\"positivity\", \"tweetid\", \"date\", \"query\", \"user\", \"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "266ace86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positivity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positivity                                              tweet\n",
       "0           0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1           0  is upset that he can't update his Facebook by ...\n",
       "2           0  @Kenichan I dived many times for the ball. Man...\n",
       "3           0    my whole body feels itchy and like its on fire \n",
       "4           0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "03b5941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter_training.drop([\"tweetid\", \"date\", \"query\", \"user\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3c215b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_training.positivity = twitter_training.positivity.replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e6779368",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = twitter_training[twitter_training.positivity == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "64414784",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = twitter_training[twitter_training.positivity == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77eeb30",
   "metadata": {},
   "source": [
    "### Clean Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8f63a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4a4724c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tweets = negative.tweet.to_list()\n",
    "positive_tweets = positive.tweet.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "05e88de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9f6d7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6ebbc9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(token_list: list) -> list:\n",
    "    lemmatized_tokens = []\n",
    "    for token, tag in pos_tag(token_list):\n",
    "        if tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        elif tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token, pos))\n",
    "    \n",
    "    return lemmatized_tokens   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3853f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(token_list: list, stop_words: list) -> list:\n",
    "    trim_characters = ['!', '.', ',', '*', '&', '%', '$', '?', '\"\"', \":\", \";\", \"(\", \")\", \"-\", \"/\"]\n",
    "    remove_characters = ['@', '#', '//']\n",
    "    cleaned_tokens = []\n",
    "    \n",
    "    for token in token_list:\n",
    "        for character in trim_characters:\n",
    "            if character in token:\n",
    "                token = token.strip(character)\n",
    "        for character in remove_characters:\n",
    "            if character in token:\n",
    "                token = ''\n",
    "                \n",
    "        if len(token) > 1 and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token)\n",
    "    \n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "595a9efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8b04d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_data  = [tweet_tokenizer.tokenize(x) for x in negative_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0023de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data  = [tweet_tokenizer.tokenize(x) for x in positive_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "2dc02679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(tweet: str) -> list:\n",
    "    token_list = tweet_tokenizer.tokenize(tweet)\n",
    "    stop_words = stopwords.words('english')\n",
    "    cleaned_tokens = clean_data(token_list, stop_words)\n",
    "    lemmatized_tokens = lemmatize(cleaned_tokens)\n",
    "    \n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d4a86137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(all_tokens: list, stop_words: list):\n",
    "    cleaned_data = []\n",
    "    for token_list in all_tokens:\n",
    "        cleaned_tokens = clean_data(token_list, stop_words)\n",
    "        lemmatized_tokens = lemmatize(cleaned_tokens)\n",
    "        cleaned_data.append(lemmatized_tokens)\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f31fbe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_negative = prepare_data(negative_data, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "1376ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_positive = prepare_data(positive_data, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5fbb3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(all_tokens: list) -> dict:\n",
    "    for token_list in all_tokens:\n",
    "        yield dict([token, True] for token in token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3893333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_model(positive_tokens: list, negative_tokens: list) -> list:\n",
    "    positive_tweets = [(positive_dict, \"Positive\") for positive_dict in convert_to_dict(positive_tokens)]\n",
    "    negative_tweets = [(negative_dict, \"Negative\") for negative_dict in convert_to_dict(negative_tokens)]\n",
    "    \n",
    "    return positive_tweets + negative_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "975b7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = prepare_data_for_model(cleaned_positive, cleaned_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f02e1",
   "metadata": {},
   "source": [
    "## Sklearn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d9d35b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3bada2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_processing)),  \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('classifier', MultinomialNB()), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5b166d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positivity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positivity                                              tweet\n",
       "0           0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1           0  is upset that he can't update his Facebook by ...\n",
       "2           0  @Kenichan I dived many times for the ball. Man...\n",
       "3           0    my whole body feels itchy and like its on fire \n",
       "4           0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "45f01294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76    162927\n",
      "           1       0.75      0.76      0.75    157073\n",
      "\n",
      "    accuracy                           0.76    320000\n",
      "   macro avg       0.76      0.76      0.76    320000\n",
      "weighted avg       0.76      0.76      0.76    320000\n",
      "\n",
      "[[122701  40226]\n",
      " [ 37709 119364]]\n",
      "0.756453125\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(twitter_training['tweet'], twitter_training['positivity'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e11389",
   "metadata": {},
   "source": [
    "## NLTK Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6dde0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ddf40027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "87f2e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1dc2cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_tweets[:round(len(all_tweets) * 0.2)]\n",
    "test = all_tweets[round(len(all_tweets) * 0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8bda2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbc = NaiveBayesClassifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "64718e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75542109375"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.accuracy(nbc, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "26e034a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 saddest = True           Negati : Positi =     37.5 : 1.0\n",
      "                  farrah = True           Negati : Positi =     29.5 : 1.0\n",
      "                  poorly = True           Negati : Positi =     26.1 : 1.0\n",
      "                  arghhh = True           Negati : Positi =     24.9 : 1.0\n",
      "                 honored = True           Positi : Negati =     24.4 : 1.0\n",
      "             condolences = True           Negati : Positi =     24.3 : 1.0\n",
      "                saddened = True           Negati : Positi =     23.6 : 1.0\n",
      "                  boohoo = True           Negati : Positi =     21.6 : 1.0\n",
      "                   arghh = True           Negati : Positi =     20.9 : 1.0\n",
      "                  gutted = True           Negati : Positi =     20.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nbc.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "31724fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df.tweet.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0ef5dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vax_data = [tweet_tokenizer.tokenize(x) for x in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "29b985c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vax_tweets = prepare_data(vax_data, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "bb879046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbc.classify(dict([token, True] for token in vax_tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5dc42989",
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = []\n",
    "positives = []\n",
    "for tweet in vax_tweets:\n",
    "    if nbc.classify(dict([token, True] for token in tweet)) == 'Negative':\n",
    "        negatives.append(tweet)\n",
    "    else:\n",
    "        positives.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0cdcdd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tokens = []\n",
    "for tweet in negatives:\n",
    "    for token in tweet:\n",
    "        negative_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "6883646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tokens = []\n",
    "for tweet in positives:\n",
    "    for token in tweet:\n",
    "        positive_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "cc0dc10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38463"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "37282a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19231"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "c74f6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_list = list(set(positive_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "bca353c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = [positive_tokens.count(x) for x in positive_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "06d67ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dict = {\n",
    "    \"token\" : positive_list,\n",
    "    \"count\" : positive_counts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "9c64d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.DataFrame.from_dict(positive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c786dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df.sort_values(by=\"count\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b737fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df[\"prevalence\"] = positive_df[\"count\"] / len(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "93476399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>vaccination</td>\n",
       "      <td>924</td>\n",
       "      <td>0.497577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>vaccine</td>\n",
       "      <td>665</td>\n",
       "      <td>0.358104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>covid</td>\n",
       "      <td>374</td>\n",
       "      <td>0.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>19</td>\n",
       "      <td>270</td>\n",
       "      <td>0.145396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>available</td>\n",
       "      <td>167</td>\n",
       "      <td>0.089930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>doses</td>\n",
       "      <td>152</td>\n",
       "      <td>0.081852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>appointments</td>\n",
       "      <td>126</td>\n",
       "      <td>0.067851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>jun</td>\n",
       "      <td>124</td>\n",
       "      <td>0.066774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>sign</td>\n",
       "      <td>122</td>\n",
       "      <td>0.065697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>code</td>\n",
       "      <td>120</td>\n",
       "      <td>0.064620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  count  prevalence\n",
       "1833   vaccination    924    0.497577\n",
       "1573       vaccine    665    0.358104\n",
       "965          covid    374    0.201400\n",
       "1284            19    270    0.145396\n",
       "4215     available    167    0.089930\n",
       "202          doses    152    0.081852\n",
       "117   appointments    126    0.067851\n",
       "596            jun    124    0.066774\n",
       "2884          sign    122    0.065697\n",
       "1812          code    120    0.064620"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "975c956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = list(set(negative_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "04738645",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = [negative_tokens.count(x) for x in token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "b68a9db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_counts) == len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "22d510ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {\n",
    "    \"token\" : token_list,\n",
    "    \"count\" : token_counts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "efa8a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = pd.DataFrame.from_dict(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "e0d2f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df.sort_values(by=\"count\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "4a0a66a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4098910310142498"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1467/len(negatives) # \"Available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "031d6c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23190835428890752"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "830/len(negatives) #appointments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "45e6c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10220486908589803"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "445/len(negatives) # slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8d829533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21497473587505742"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "936 / len(negatives) # walgreens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "1b7ebe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df[\"prevalence\"] = token_df[\"count\"] / len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "612709ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>vaccine</td>\n",
       "      <td>2283</td>\n",
       "      <td>0.637888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>vaccination</td>\n",
       "      <td>1467</td>\n",
       "      <td>0.409891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5783</th>\n",
       "      <td>available</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.351215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>appointments</td>\n",
       "      <td>830</td>\n",
       "      <td>0.231908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>walgreens</td>\n",
       "      <td>817</td>\n",
       "      <td>0.228276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>sign</td>\n",
       "      <td>776</td>\n",
       "      <td>0.216820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>code</td>\n",
       "      <td>775</td>\n",
       "      <td>0.216541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>jun</td>\n",
       "      <td>775</td>\n",
       "      <td>0.216541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>zip</td>\n",
       "      <td>773</td>\n",
       "      <td>0.215982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>jul</td>\n",
       "      <td>772</td>\n",
       "      <td>0.215703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             token  count  prevalence\n",
       "541        vaccine   2283    0.637888\n",
       "5032   vaccination   1467    0.409891\n",
       "5783     available   1257    0.351215\n",
       "4474  appointments    830    0.231908\n",
       "3369     walgreens    817    0.228276\n",
       "5366          sign    776    0.216820\n",
       "2083          code    775    0.216541\n",
       "1701           jun    775    0.216541\n",
       "2859           zip    773    0.215982\n",
       "1543           jul    772    0.215703"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "0ddb792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df.to_csv(\"../data/token_prevalence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d8855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nih",
   "language": "python",
   "name": "nih"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
